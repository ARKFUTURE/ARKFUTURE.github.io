%YAML 1.1
---
# ARKFUTURE 使用的suricata配置
# 全局搜索:
#   协议相关配置请搜索---协议配置相关;网络配置相关请搜索---配置网络;网卡修改请搜索---网卡设置
#
# suricata配置文件. 除了描述此文件中所有选项的注释之外, 完整的文档可在:
# https://suricata.readthedocs.io/en/latest/configuration/suricata-yaml.html
#

##
## Step 1: 配置网络
##

vars:
  # 越具体 警报的准确性和性能越好
  address-groups:
    #HOME_NET: "[192.168.0.0/16,10.0.0.0/8,172.16.0.0/12]"
    #HOME_NET: "[192.168.0.0/16]"
    #HOME_NET: "[10.0.0.0/8]"
    #HOME_NET: "[172.16.0.0/12]"
    HOME_NET: "any"

    #EXTERNAL_NET: "!$HOME_NET"
    EXTERNAL_NET: "any"

    HTTP_SERVERS: "$HOME_NET"
    SMTP_SERVERS: "$HOME_NET"
    SQL_SERVERS: "$HOME_NET"
    DNS_SERVERS: "$HOME_NET"
    TELNET_SERVERS: "$HOME_NET"
    AIM_SERVERS: "$EXTERNAL_NET"
    DC_SERVERS: "$HOME_NET"
    DNP3_SERVER: "$HOME_NET"
    DNP3_CLIENT: "$HOME_NET"
    MODBUS_CLIENT: "$HOME_NET"
    MODBUS_SERVER: "$HOME_NET"
    ENIP_CLIENT: "$HOME_NET"
    ENIP_SERVER: "$HOME_NET"

  port-groups:
    HTTP_PORTS: "80"
    SHELLCODE_PORTS: "!80"
    ORACLE_PORTS: 1521
    SSH_PORTS: 22
    DNP3_PORTS: 20000
    MODBUS_PORTS: 502
    FILE_DATA_PORTS: "[$HTTP_PORTS,110,143]"
    FTP_PORTS: 21
    GENEVE_PORTS: 6081
    VXLAN_PORTS: 4789
    TEREDO_PORTS: 3544

##
## Step 2: 选择要启用的输出(日志输出) 协议配置相关
##

# 默认的日志记录目录
# 如果未指定完整的路径名 则任何日志或输出文件都将放置在此处
# 这可以用-l命令行参数覆盖
default-log-dir: /var/log/suricata/

# 全局统计配置
stats:
  enabled: yes
  # 间隔字段(以秒为单位)控制在日志中更新统计信息的间隔
  interval: 8
  # 将解码事件添加到统计数据
  #decoder-events: true
  # 统计数据中的解码器事件前缀
  # 以前曾是 "解码器",但这导致eve.stats记录中缺少事件,参见#2225
  #decoder-events-prefix: "decoder.event"
  # 将流事件添加为统计数据
  #stream-events: false

# 配置您想要的警报(和其他)日志记录的类型
outputs:
  # 类似于snort的快速日志的基于行的警报日志
  - fast:
      enabled: yes
      filename: fast.log
      append: yes
      #filetype: regular 
      #文件类型 'regular', 'unix_stream' or 'unix_dgram'

  # json格式的可扩展事件格式(昵称为eve)事件日志
  - eve-log:
      enabled: yes
      filetype: regular 
      #文件类型 regular|syslog|unix_dgram|unix_stream|redis
      filename: eve.json
      # 启用多线程eve.json输出
      #threaded: false
      #prefix: "@cee: " 
      # 每个日志条目的前缀
      # 当 type: syslog 以下内容有效
      #identity: "suricata"
      #facility: local5
      #level: Info ## 可能级别: Emergency, Alert, Critical,Error, Warning, Notice, Info, Debug
      #ethernet: no  # 在事件中记录以太网标头
      #redis:
      #  server: 127.0.0.1
      #  port: 6379
      #  async: true 
      #  mode: list 
      #  key: suricata ##要使用的密钥或通道 默认为suricata
      #  pipelining:
      #    enabled: yes ## 将enable设置为yes以启用查询流水线
      #    batch-size: 10 ## 要保存在缓冲区中的条目数

      # 包括顶级元数据 默认为yes
      #metadata: no

      # 在pcap文件处理模式中包括输入pcap文件的名称
      pcap-file: false

      # 社区流ID
      # 将 community_id 字段添加到EVE记录中 
      # 这些旨在为记录提供一个可预测的流ID
      # 该ID可用于将记录与其他工具（如Zeek（Bro））的输出进行匹配
      #
      # 需要一个 'seed' 它需要在传感器和工具之间保持一致 以降低id的可预测性
      # 

      # 启用/禁用社区id功能
      community-id: false
      # ID输出的种子值 有效值为0-65535
      community-id-seed: 0

      # 
      xff:
        enabled: no
        # 有两种操作模式: "extra-data" and "overwrite".
        mode: extra-data
        # 支持两种代理部署: "reverse" and "forward". In
        # "reverse" 部署使用的IP地址是最后一个
        # "forward" 部署使用第一个IP地址
        deployment: reverse
        # 将报告实际IP地址的标头名称
        # 如果存在多个IP地址 则最后一个IP地址将被考虑在内
        # 
        header: X-Forwarded-For

      types:
        - alert:
            # payload: yes             # 启用Base64中的转储有效负载
            # payload-buffer-size: 4kb # 要在eve日志中输出的有效负载缓冲的最大大小
            # payload-printable: yes   # 启用以可打印 (lossy) 格式转储有效负载
            # packet: yes              # 启用数据包转储 (without stream segments)
            # metadata: no             # 允许在警报中包含应用层元数据. 默认 yes
            # http-body: yes           # 需要元数据;启用在Base64中转储HTTP正文
            # http-body-printable: yes # 需要元数据;启用以可打印格式转储HTTP正文

            # 使用 "tag" 关键字为规则启用标记数据包的日志记录
            tagged-packets: yes
        - anomaly:
            enabled: yes
            types:
              # decode: no
              # stream: no
              # applayer: yes
            #packethdr: no
        - http:
            extended: yes
            #custom: [Accept-Encoding, Accept-Language, Authorization]
            # dump-all-headers: none
        - dns:
            # 此配置使用新的DNS日志记录格式

            #version: 2
            #enabled: yes

            # 控制请求和响应的日志记录:
            # - requests: 启用DNS查询的日志记录
            # - responses: 启用DNS应答的日志记录
            # 默认情况下会记录请求和响应.
            #requests: no
            #responses: no

            # 应答记录格式:
            # - detailed: 每个答案的数组项
            # - grouped: 按类型聚合的答案
            # 默认值: all
            #formats: [detailed, grouped]

            # 要记录的DNS记录类型 基于查询类型.
            # 默认值: all.
            #types: [a, aaaa, cname, mx, ns, ptr, txt]
        - tls:
            extended: yes
            # 使用会话id恢复会话的输出TLS事务
            #session-resumption: no
            # 自定义控制eve日志中包含的TLS字段
            #custom: [subject, issuer, session_resumed, serial, fingerprint, sni, version, not_before, not_after, certificate, chain, ja3, ja3s]
        - files:
            force-magic: no   
            # 在所有记录的文件上强制记录魔术强制记录校验和 可用的哈希函数有 md5/sha1/sha256
            #force-hash: [md5]
        - drop:
        #    alerts: yes      # 记录导致下降的警报
        #    flows: all       # start or all: 'start' 只记录每个流动方向的单个液滴. 所有日志每个都丢弃 pkt.
        - smtp:
            #extended: yes 
            #custom: [received, x-mailer, x-originating-ip, relays, reply-to, bcc]
            #md5: [body, subject]
        - dnp3
        - ftp
        - rdp
        - nfs
        - smb
        - tftp
        - ikev2
        - dcerpc
        - krb5
        - snmp
        - rfb
        - sip
        - dhcp:
            enabled: yes
            extended: no
        - ssh
        - mqtt:
            # passwords: yes
        - http2
        - stats:
            totals: yes
            threads: no
            deltas: no
        - flow
        #- netflow
        #- metadata

  # 基于行的HTTP请求日志（无警报）
  - http-log:
      enabled: no
      filename: http.log
      append: yes
      #extended: yes     # enable this for extended logging information
      #custom: yes       # enable the custom logging format (defined by customformat)
      #customformat: "%{%D-%H:%M:%S}t.%z %{X-Forwarded-For}i %H %m %h %u %s %B %a:%p -> %A:%P"
      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'

  # TLS握手参数的基于行的日志（无警报）
  - tls-log:
      enabled: no  # Log TLS connections.
      filename: tls.log # File to store TLS logs.
      append: yes
      #extended: yes     # Log extended information like fingerprint
      #custom: yes       # enabled the custom logging format (defined by customformat)
      #customformat: "%{%D-%H:%M:%S}t.%z %a:%p -> %A:%P %v %n %d %D"
      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'
      # output TLS transaction where the session is resumed using a
      # session id
      #session-resumption: no

  # 将证书链存储到磁盘的输出模块
  - tls-store:
      enabled: no
      #certs-log-dir: certs # directory to store the certificates files

  # 数据包日志 以pcap格式记录数据包. 3 modes of operation: "normal" "multi" and "sguil"
  - pcap-log:
      enabled: no
      filename: log.pcap

      # File size limit.  Can be specified in kb, mb, gb.  Just a number
      # is parsed as bytes.
      limit: 1000mb

      # If set to a value, ring buffer mode is enabled. Will keep maximum of
      # "max-files" of size "limit"
      max-files: 2000

      # Compression algorithm for pcap files. Possible values: none, lz4.
      # Enabling compression is incompatible with the sguil mode. Note also
      # that on Windows, enabling compression will *increase* disk I/O.
      compression: none

      # Further options for lz4 compression. The compression level can be set
      # to a value between 0 and 16, where higher values result in higher
      # compression.
      #lz4-checksum: no
      #lz4-level: 0

      mode: normal # normal, multi or sguil.

      # Directory to place pcap files. If not provided the default log
      # directory will be used. Required for "sguil" mode.
      #dir: /nsm_data/

      #ts-format: usec # sec or usec second format (default) is filename.sec usec is filename.sec.usec
      use-stream-depth: no #If set to "yes" packets seen after reaching stream inspection depth are ignored. "no" logs all packets
      honor-pass-rules: no # If set to "yes", flows in which a pass rule matched will stop being logged.

  # 一个完整的警报日志,包含许多信息,供签名作者或调查可疑的误报
  - alert-debug:
      enabled: no
      filename: alert-debug.log
      append: yes
      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'

  # 前奏的警报输出(https://www.prelude-siem.org/)仅当使用-enable prelude编译Suricata时可用
  - alert-prelude:
      enabled: no
      profile: suricata
      log-packet-content: no
      log-packet-header: yes

  # Stats.log包含来自Suricata引擎的各种计数器的数据
  - stats:
      enabled: yes
      filename: stats.log
      append: yes       # append to file (yes) or overwrite it (no)
      totals: yes       # stats for all threads merged together
      threads: no       # per thread stats
      #null-values: yes  # print counters that have value 0. Default: no

  # 将类似于fast.log的基于行的警报日志记录到syslog中
  - syslog:
      enabled: no
      # reported identity to syslog. If omitted the program name (usually
      # suricata) will be used.
      #identity: "suricata"
      facility: local5
      #level: Info ## possible levels: Emergency, Alert, Critical,
                   ## Error, Warning, Notice, Info, Debug

  # 用于在磁盘上存储文件的输出模块
  - file-store:
      version: 2
      enabled: no

      #dir: filestore

      #write-fileinfo: yes

      # 强制存储所有文件. Default: no.
      #force-filestore: yes

      # 覆盖要在其中执行文件提取的会话的全局流深度
      #stream-depth: 0

      #max-open-files: 1000


      #force-hash: [sha1, md5]

      xff:
        enabled: no
        # 有两种操作模式可用, "extra-data" and "overwrite".
        mode: extra-data
        # 支持两个代理部署, "reverse" and "forward". 
        # In a "reverse" deployment the IP address used is the last one, 
        # in a "forward" deployment the first IP address is used.
        deployment: reverse
        # 将报告实际ip地址的标头名称. 
        # 如果存在多个ip地址 则将考虑最后一个ip地址.
        header: X-Forwarded-For

  # 流规范化后的日志tcp数据
  # 两种类型: file or dir:
  #     - file logs into a single logfile.
  #     - dir creates 2 files per TCP session and stores the raw TCP data into them.
  # Use 'both' to enable both file and dir modes.
  #
  # Note: 受 "stream.reassembly.depth" 限制
  - tcp-data:
      enabled: no
      type: file
      filename: tcp-data.log

  # 正常化后记录HTTP正文数据, de-chunking 和 unzipping.
  # 两种类型: file or dir.
  #     - 文件记录到单个日志文件中.
  #     - dir为每个HTTP会话创建2个文件，并将规范化的数据存储到其中
  # 使用 both 同时启用文件和目录模式.
  #
  # Note: 受限制
  - http-body-data:
      enabled: no
      type: file
      filename: http-data.log

  # lua输出支持 - 执行lua脚本以生成警报和事件输出
  # 记录于:
  # https://suricata.readthedocs.io/en/latest/output/lua-output.html
  - lua:
      enabled: no
      #scripts-dir: /etc/suricata/lua-output/
      scripts:
      #   - script1.lua

# 日志记录配置.  这与记录IDS无关 alerts/events
# 但是关于suricata正在做什么的输出, 像 startup messages, errors, etc.
logging:
  # 默认日志级别: 可以在输出节中重写.
  # 该值由 SC_LOG_LEVEL 覆盖.
  default-log-level: notice

  # 默认输出格式.
  # 该值由 SC_LOG_FORMAT 覆盖.
  #default-log-format: "[%i] %t - (%f:%l) <%d> (%n) -- "

  # 用于筛选输出的正则表达式. 
  # 该值由 SC_LOG_OP_FILTER 覆盖.
  default-output-filter:

  # 在配置和构建suricata时,要求libunwind可用.
  # 如果信号意外终止suricata 如果启用 则显示一条简短的诊断消息 其中包含有问题的堆栈
  #stacktrace-on-signal: on

  # 定义日志输出.  如果没有定义 或者它们都被禁用 您将获得默认值: console output.
  outputs:
  - console:
      enabled: yes
      # type: json
  - file:
      enabled: yes
      level: info
      filename: suricata.log
      # type: json
  - syslog:
      enabled: no
      facility: local5
      format: "[%i] <%d> -- "
      # type: json


##
## Step 3: 配置常用捕获设置
##
## 有关更多选项 包括Netmap和PF_RING 请参阅下面的“高级捕获选项”
##

# linux高速捕获支持
af-packet:
    # 网卡设置
  - interface: eth0
    # 接收线程数. "auto" 使用核心数量
    #threads: auto
    # 默认群集. AF_PACKET将根据流量对数据包进行负载平衡
    cluster-id: 99
    # 默认的AF_PACKET群集类型.
    # 可能的值为:
    #  * cluster_flow: 给定流的所有数据包都发送到同一个套接字
    #  * cluster_cpu: CPU在内核中处理的所有数据包都发送到同一个套接字
    #  * cluster_qm: 由网卡链接到RSS队列的所有数据包都被发送到同一个套接字
    #  * cluster_ebpf: ebpf文件负载平衡
    cluster-type: cluster_flow
    # 在某些碎片情况下, 无法计算哈希. 如果 "defrag" 设置为 yes, 内核将在发送数据包之前进行所需的碎片整理
    defrag: yes
    # 使用的环形功能 AF_PACKET, 那么 'use-mmap' 设置为 yes
    #use-mmap: yes
    # 锁定内存映射以避免其被交换
    # 请注意,过度订阅可能会锁定您的系统
    #mmap-locked: yes
    # 使用tpacket_v3捕获模式, 只有当use-mmap为true时才处于活动状态
    # 不要在ips或tap模式中使用它,因为它会导致严重的延迟
    #tpacket-v3: yes
    # 环大小将根据 "max-pending-packets" 和 线程数 进行计算
    # 您可以通过设置以下值手动设置以数据包数量为单位的环形大小
    # 如果您使用流 "cluster-type" 并且具有真正的网络密集型单流
    # 则可能需要独立于数字设置"ring-size" 
    # 线程:
    #ring-size: 2048
    # 块大小仅由 tpacket_v3 使用
    # 它应该设置为一个足够高的值 以包含相当数量的数据包
    # 大小以字节为单位 因此请考虑您的MTU 它应该是2的幂 并且必须是页面大小 通常为4096 的倍数
    #block-size: 32768
    # tpacket_v3 块超时: 如果在块超时毫秒后未填充打开的块,则将其传递给用户空间
    #block-timeout: 10
    # 在繁忙的系统上, 将其设置为 "yes" 以帮助从数据包丢失阶段恢复
    # 这将导致某些数据包 最多为环形冲洗 未被检查
    #use-emergency-flush: yes
    # recv缓冲区大小, 增加值可以提高性能
    # buffer-size: 32768
    # 设置为yes可禁用混杂模式
    # disable-promisc: no
    # 为接口选择校验和验证模式. 在捕获的时刻
    # 由于校验和计算被卸载到网卡 一些分组可能具有无效的校验和
    # 可能的值为:
    #  - kernel: 使用内核为每个数据包发送的指示 (default)
    #  - yes: 强制进行校验和验证
    #  - no: 校验和验证被禁用
    #  - auto: suricata使用统计方法来检测
    #  使用校验和卸载
    # 警告: 'capture.checksum-validation' 必须设置为 "yes" 才能进行任何验证
    #checksum-checks: kernel
    # 应用于此接口的BPF筛选器. 此处应用PCAP筛选器语法.
    #bpf-filter: port 80 or udp
    # 您可以使用以下变量激活AF_PACKET抽头或IPS模式
    # 如果复制模式设置为ips或tap, 则到达当前接口的流量将复制到复制iface接口
    # 如果设置了 'tap' 则复制完成 如果设置了 'ips' , 则与 'drop' 操作匹配的数据包将不会被复制
    #copy-mode: ips
    #copy-iface: eth1
    #  有关eBPF和XDP设置 包括旁路 过滤器和负载平衡
    #  看 doc/userguide/capture-hardware/ebpf-xdp.rst 
  # 在此处放置默认值. 这些将用于不在上面列表中的接口
  - interface: default
    #threads: auto
    #use-mmap: no
    #tpacket-v3: yes

# 跨平台libpcap捕获支持 
pcap:
    # 网卡设置
  - interface: eth0
    # 在linux上, pcap将尝试使用mmap的捕获，并将使用 "buffer-size" 作为环使用的总内存. 
    # 所以将其设置为大于带宽的1%
    #buffer-size: 16777216
    #bpf-filter: "tcp and port 25"
    # 为接口选择校验和验证模式
    # 在捕获的时刻 由于校验和计算被卸载到网卡 一些分组可能具有无效的校验和
    # 可能的值为:
    #  - yes: 强制进行校验和验证
    #  - no: 已禁用校验和验证
    #  - auto: suricata使用统计方法来检测何时使用校验和卸载. (default)
    # Warning: 'capture.checksum-validation' 必须设置为 yes 才能进行任何验证
    #checksum-checks: auto
    # 对于一些使用修改的libpcap的加速器卡
    # 您可能希望捕获线程的数量与捕获环的数量相同
    # 在这种情况下, 将threads变量设置为N，以启动在同一接口上侦听的N个线程
    #threads: 16
    # 设置为否以禁用混杂模式:
    #promisc: no
    # 设置snaplen, 如果未设置 则默认为MTU 如果可以通过ioctl调用知道MTU 如果不设置 则为完全捕获
    #snaplen: 1518
  # 在此处放置默认值
  - interface: default
    #checksum-checks: auto

# 读取pcap文件的设置
pcap-file:
  # 可能的值为:
  #  - yes: 强制进行校验和验证
  #  - no: 校验和验证被禁用
  #  - auto: suricata使用统计方法来检测何时使用校验和卸载. (default)
  # Warning: 'checksum-validation' 必须设置为 yes 才能测试校验和
  checksum-checks: auto

# 有关更多选项，包括Netmap和PF_RING，请参阅下面的“高级捕获选项”。


##
## Step 4: 应用层协议配置 协议配置相关
##

# 配置应用层解析器。
#
# 错误策略设置适用于所有应用层解析器。
# 值可以是"drop-flow", "pass-flow", "bypass", "drop-packet", "pass-packet", "reject" or "ignore" (the default).
#
# 协议部分详细介绍了每个协议
#
# 选项 "enabled" takes 3 values - "yes", "no", "detection-only".
# "yes" 启用检测和解析器, "no" 禁用两者, 和 "detection-only" 仅启用协议检测 (parser disabled).
app-layer:
  # error-policy: ignore
  protocols:
    rfb:
      enabled: yes
      detection-ports:
        dp: 5900, 5901, 5902, 5903, 5904, 5905, 5906, 5907, 5908, 5909
    # MQTT, disabled by default.
    mqtt:
      enabled: yes
      # max-msg-length: 1mb
      # subscribe-topic-match-limit: 100
      # unsubscribe-topic-match-limit: 100
      # Maximum number of live MQTT transactions per flow
      # max-tx: 4096
    krb5:
      enabled: yes
    snmp:
      enabled: yes
    ikev2:
      enabled: yes
    tls:
      enabled: yes
      detection-ports:
        dp: 443

      # 从客户端hello生成JA3指纹
      # 如果未指定，则默认情况下将禁用, 但在规则需要时启用.
      #ja3-fingerprints: auto

      # 加密通信启动时该怎么办:
      # - default: 保持跟踪TLS会话 检查协议异常 检查tls_*关键字
      #            禁用检查未修改的'content' 签名
      # - bypass:  尽可能多地停止处理此流 没有进一步的TLS解析和检查。如果可能的话，分流到内核或硬件
      # - full:    保持正常的跟踪和检查
      #            还将检查未修改的内容关键字签名
      #
      # 为了获得最佳性能 请选择 'bypass'.
      #
      #encryption-handling: default

    dcerpc:
      enabled: yes
    ftp:
      enabled: yes
      # memcap: 64mb
    rdp:
      enabled: yes
    ssh:
      enabled: yes
      #hassh: yes
    # HTTP2: 实验性的HTTP2支持。默认情况下已禁用.
    http2:
      enabled: no
      # 在HTTP2流量上使用http关键字 
      http1-rules: no
    smtp:
      enabled: yes
      raw-extraction: no
      # Configure SMTP-MIME Decoder
      mime:
        # Decode MIME messages from SMTP transactions
        # (may be resource intensive)
        # This field supersedes all others because it turns the entire
        # process on or off
        decode-mime: yes

        # Decode MIME entity bodies (ie. Base64, quoted-printable, etc.)
        decode-base64: yes
        decode-quoted-printable: yes

        # Maximum bytes per header data value stored in the data structure
        # (default is 2000)
        header-value-depth: 2000

        # Extract URLs and save in state data structure
        extract-urls: yes
        # Set to yes to compute the md5 of the mail body. You will then
        # be able to journalize it.
        body-md5: no
      # Configure inspected-tracker for file_data keyword
      inspected-tracker:
        content-limit: 100000
        content-inspect-min-size: 32768
        content-inspect-window: 4096
    imap:
      enabled: detection-only
    smb:
      enabled: yes
      detection-ports:
        dp: 139, 445

      # Stream reassembly size for SMB streams. By default track it completely.
      #stream-depth: 0

    nfs:
      enabled: yes
    tftp:
      enabled: yes
    dns:
      tcp:
        enabled: yes
        detection-ports:
          dp: 53
      udp:
        enabled: yes
        detection-ports:
          dp: 53
    http:
      enabled: yes
      # memcap:                   Maximum memory capacity for HTTP
      #                           Default is unlimited, values can be 64mb, e.g.

      # default-config:           Used when no server-config matches
      #   personality:            List of personalities used by default
      #   request-body-limit:     Limit reassembly of request body for inspection
      #                           by http_client_body & pcre /P option.
      #   response-body-limit:    Limit reassembly of response body for inspection
      #                           by file_data, http_server_body & pcre /Q option.
      #
      #   For advanced options, see the user guide


      # server-config:            List of server configurations to use if address matches
      #   address:                List of IP addresses or networks for this block
      #   personality:            List of personalities used by this block
      #
      #                           Then, all the fields from default-config can be overloaded
      #
      # Currently Available Personalities:
      #   Minimal, Generic, IDS (default), IIS_4_0, IIS_5_0, IIS_5_1, IIS_6_0,
      #   IIS_7_0, IIS_7_5, Apache_2
      libhtp:
         default-config:
           personality: IDS

           # Can be specified in kb, mb, gb.  Just a number indicates
           # it's in bytes.
           request-body-limit: 100kb
           response-body-limit: 100kb

           # inspection limits
           request-body-minimal-inspect-size: 32kb
           request-body-inspect-window: 4kb
           response-body-minimal-inspect-size: 40kb
           response-body-inspect-window: 16kb

           # response body decompression (0 disables)
           response-body-decompress-layer-limit: 2

           # auto will use http-body-inline mode in IPS mode, yes or no set it statically
           http-body-inline: auto

           # Decompress SWF files.
           # Two types: 'deflate', 'lzma', 'both' will decompress deflate and lzma
           # compress-depth:
           # Specifies the maximum amount of data to decompress,
           # set 0 for unlimited.
           # decompress-depth:
           # Specifies the maximum amount of decompressed data to obtain,
           # set 0 for unlimited.
           swf-decompression:
             enabled: yes
             type: both
             compress-depth: 100kb
             decompress-depth: 100kb

           # Use a random value for inspection sizes around the specified value.
           # This lowers the risk of some evasion techniques but could lead
           # to detection change between runs. It is set to 'yes' by default.
           #randomize-inspection-sizes: yes
           # If "randomize-inspection-sizes" is active, the value of various
           # inspection size will be chosen from the [1 - range%, 1 + range%]
           # range
           # Default value of "randomize-inspection-range" is 10.
           #randomize-inspection-range: 10

           # decoding
           double-decode-path: no
           double-decode-query: no

           # Can enable LZMA decompression
           #lzma-enabled: false
           # Memory limit usage for LZMA decompression dictionary
           # Data is decompressed until dictionary reaches this size
           #lzma-memlimit: 1mb
           # Maximum decompressed size with a compression ratio
           # above 2048 (only LZMA can reach this ratio, deflate cannot)
           #compression-bomb-limit: 1mb
           # Maximum time spent decompressing a single transaction in usec
           #decompression-time-limit: 100000

         server-config:

           #- apache:
           #    address: [192.168.1.0/24, 127.0.0.0/8, "::1"]
           #    personality: Apache_2
           #    # Can be specified in kb, mb, gb.  Just a number indicates
           #    # it's in bytes.
           #    request-body-limit: 4096
           #    response-body-limit: 4096
           #    double-decode-path: no
           #    double-decode-query: no

           #- iis7:
           #    address:
           #      - 192.168.0.0/24
           #      - 192.168.10.0/24
           #    personality: IIS_7_0
           #    # Can be specified in kb, mb, gb.  Just a number indicates
           #    # it's in bytes.
           #    request-body-limit: 4096
           #    response-body-limit: 4096
           #    double-decode-path: no
           #    double-decode-query: no

    # Note: Modbus probe parser is minimalist due to the limited usage in the field.
    # Only Modbus message length (greater than Modbus header length)
    # and protocol ID (equal to 0) are checked in probing parser
    # It is important to enable detection port and define Modbus port
    # to avoid false positives
    modbus:
      # How many unanswered Modbus requests are considered a flood.
      # If the limit is reached, the app-layer-event:modbus.flooded; will match.
      #request-flood: 500

      enabled: no
      detection-ports:
        dp: 502
      # According to MODBUS Messaging on TCP/IP Implementation Guide V1.0b, it
      # is recommended to keep the TCP connection opened with a remote device
      # and not to open and close it for each MODBUS/TCP transaction. In that
      # case, it is important to set the depth of the stream reassembling as
      # unlimited (stream.reassembly.depth: 0)

      # Stream reassembly size for modbus. By default track it completely.
      stream-depth: 0

    # DNP3
    dnp3:
      enabled: no
      detection-ports:
        dp: 20000

    # SCADA EtherNet/IP and CIP protocol support
    enip:
      enabled: no
      detection-ports:
        dp: 44818
        sp: 44818

    ntp:
      enabled: yes

    dhcp:
      enabled: yes

    sip:
      enabled: yes

# 要解码的最大asn1帧数的限制 (default 256)
asn1-max-frames: 256

# 数据集默认设置
# datasets:
#   # Default fallback memcap and hashsize values for datasets in case these
#   # were not explicitly defined.
#   defaults:
#     memcap: 100mb
#     hashsize: 2048

##############################################################################
##
## 下面的高级设置
##
##############################################################################

##
## 运行选项 (默认)
##

# 使用特定的用户id和组id运行suricata:
#run-as:
#  user: suri
#  group: suri

# 某些日志记录模块将在事件中使用该名称作为标识符. 默认值为主机名
#sensor-name: suricata

# pid文件的默认位置. The pid file is only used in
# daemon mode (start Suricata with -D). If not running in daemon mode
# the --pidfile command line option must be used to create a pid file.
#pid-file: /var/run/suricata.pid

# 守护程序工作目录
# Suricata will change directory to this one if provided
# Default: "/"
#daemon-directory: "/"

# Umask.
# Suricata will use this umask if it is provided. By default it will use the
# umask passed on by the shell.
#umask: 022

# suricata核心转储配置. Limits the size of the core dump file to
# approximately max-dump. The actual core dump size will be a multiple of the
# page size. Core dumps that would be larger than max-dump are truncated. On
# Linux, the actual core dump size may be a few pages larger than max-dump.
# Setting max-dump to 0 disables core dumping.
# Setting max-dump to 'unlimited' will give the full core dump file.
# On 32-bit Linux, a max-dump value >= ULONG_MAX may cause the core dump size
# to be 'unlimited'.

coredump:
  max-dump: unlimited

# 如果suricata盒子是嗅探网络的路由器, 则设置 'router'.
# 如果是纯嗅探设置, 则设置 'sniffer-only'.
# 如果设置为auto，则自动切换 'router' in IPS mode
# and 'sniffer-only' in IDS mode.
# This feature is currently only used by the reject* keywords.
host-mode: auto

# 每个线程预先分配的数据包数. The default is 1024. A higher number 
# will make sure each CPU will be more easily kept busy, but may negatively 
# impact caching.
#max-pending-packets: 1024

# 应使用的运行模式. Please check --list-runmodes to get the available
# runmodes for each packet acquisition method. Default depends on selected capture
# method. 'workers' generally gives best performance.
#runmode: autofp

# Specifies the kind of flow load balancer used by the flow pinned autofp mode.
#
# Supported schedulers are:
#
# hash     - Flow assigned to threads using the 5-7 tuple hash.
# ippair   - Flow assigned to threads using addresses only.
#
#autofp-scheduler: hash

# 每个数据包的预分配大小. Default is 1514 which is the classical
# size for pcap on Ethernet. You should adjust this value to the highest
# packet size (MTU + hardware header) on your system.
#default-packet-size: 1514

# unix命令套接字 可用于将命令传递给suricata.
# An external tool can then connect to get information from Suricata
# or trigger some modifications of the engine. Set enabled to yes
# to activate the feature. In auto mode, the feature will only be
# activated in live capture mode. You can use the filename variable to set
# the file name of the socket.
unix-command:
  enabled: yes
  filename: /var/run/suricata-command.socket

# Magic file. The extension .mgc is added to the value here.
#magic-file: /usr/share/file/magic
#magic-file: 

# GeoIP2 数据文件. Specify path and filename of GeoIP2 database
# if using rules with "geoip" rule option.
#geoip-database: /usr/local/share/GeoLite2/GeoLite2-Country.mmdb

legacy:
  uricontent: enabled

##
## 检测设置
##

# 根据操作设置警报的顺序
# The default order is pass, drop, reject, alert
# action-order:
#   - pass
#   - drop
#   - reject
#   - alert

# 定义同一数据包可以触发的最大警报数. Default is 15
#packet-alert-max: 15

# IP 名誉
#reputation-categories-file: /etc/suricata/iprep/categories.txt
#default-reputation-path: /etc/suricata/iprep
#reputation-files:
# - reputation.list

# 使用选项运行时 --engine-analysis, the engine will read each of
# the parameters below, and print reports for each of the enabled sections
# and exit.  The reports are printed to a file in the default log dir
# given by the parameter "default-log-dir", with engine reporting
# subsection below printing reports in its own report file.
engine-analysis:
  # enables printing reports for fast-pattern for every rule.
  rules-fast-pattern: yes
  # enables printing reports for each rule
  rules: yes

#支持PCRE的递归和匹配极限
pcre:
  match-limit: 3500
  match-limit-recursion: 1500

##
## 高级交通跟踪和重建设置 (默认)
##

# 用于碎片整理和TCP流重组的主机特定策略
# 主机操作系统查找是使用基数树完成的
# 就像路由表一样，所以最具体的条目是匹配的
host-os-policy:
  # 设置默认策略窗口
  windows: [0.0.0.0/0]
  bsd: []
  bsd-right: []
  old-linux: []
  linux: []
  old-solaris: []
  solaris: []
  hpux10: []
  hpux11: []
  irix: []
  macos: []
  vista: []
  windows2k3: []

# Defrag settings:

# The memcap-policy value can be "drop-flow", "pass-flow", "bypass",
# "drop-packet", "pass-packet", "reject" or "ignore" (which is the default).
defrag:
  memcap: 32mb
  # memcap-policy: ignore
  hash-size: 65536
  trackers: 65535 # number of defragmented flows to follow
  max-frags: 65535 # number of fragments to keep (higher than trackers)
  prealloc: yes
  timeout: 60

# Enable defrag per host settings
#  host-config:
#
#    - dmz:
#        timeout: 30
#        address: [192.168.1.0/24, 127.0.0.0/8, 1.1.1.0/24, 2.2.2.0/24, "1.1.1.1", "2.2.2.2", "::1"]
#
#    - lan:
#        timeout: 45
#        address:
#          - 192.168.0.0/24
#          - 192.168.10.0/24
#          - 172.16.14.0/24

# Flow settings:
# By default, the reserved memory (memcap) for flows is 32MB. This is the limit
# for flow allocation inside the engine. You can change this value to allow
# more memory usage for flows.
# The hash-size determines the size of the hash used to identify flows inside
# the engine, and by default the value is 65536.
# At startup, the engine can preallocate a number of flows, to get better
# performance. The number of flows preallocated is 10000 by default.
# emergency-recovery is the percentage of flows that the engine needs to
# prune before clearing the emergency state. The emergency state is activated
# when the memcap limit is reached, allowing new flows to be created, but
# pruning them with the emergency timeouts (they are defined below).
# If the memcap is reached, the engine will try to prune flows
# with the default timeouts. If it doesn't find a flow to prune, it will set
# the emergency bit and it will try again with more aggressive timeouts.
# If that doesn't work, then it will try to kill the oldest flows using
# last time seen flows.
# The memcap can be specified in kb, mb, gb.  Just a number indicates it's
# in bytes.
# The memcap-policy can be "drop-flow", "pass-flow", "bypass", "drop-packet",
# "pass-packet", "reject" or "ignore" (which is the default).

flow:
  memcap: 128mb
  #memcap-policy: ignore
  hash-size: 65536
  prealloc: 10000
  emergency-recovery: 30
  #managers: 1 # default to one flow manager
  #recyclers: 1 # default to one flow recycler thread

# This option controls the use of VLAN ids in the flow (and defrag)
# hashing. Normally this should be enabled, but in some (broken)
# setups where both sides of a flow are not tagged with the same VLAN
# tag, we can ignore the VLAN id's in the flow hashing.
vlan:
  use-for-tracking: true

# Specific timeouts for flows. Here you can specify the timeouts that the
# active flows will wait to transit from the current state to another, on each
# protocol. The value of "new" determines the seconds to wait after a handshake or
# stream startup before the engine frees the data of that flow it doesn't
# change the state to established (usually if we don't receive more packets
# of that flow). The value of "established" is the amount of
# seconds that the engine will wait to free the flow if that time elapses
# without receiving new packets or closing the connection. "closed" is the
# amount of time to wait after a flow is closed (usually zero). "bypassed"
# timeout controls locally bypassed flows. For these flows we don't do any other
# tracking. If no packets have been seen after this timeout, the flow is discarded.
#
# There's an emergency mode that will become active under attack circumstances,
# making the engine to check flow status faster. This configuration variables
# use the prefix "emergency-" and work similar as the normal ones.
# Some timeouts doesn't apply to all the protocols, like "closed", for udp and
# icmp.

flow-timeouts:

  default:
    new: 30
    established: 300
    closed: 0
    bypassed: 100
    emergency-new: 10
    emergency-established: 100
    emergency-closed: 0
    emergency-bypassed: 50
  tcp:
    new: 60
    established: 600
    closed: 60
    bypassed: 100
    emergency-new: 5
    emergency-established: 100
    emergency-closed: 10
    emergency-bypassed: 50
  udp:
    new: 30
    established: 300
    bypassed: 100
    emergency-new: 10
    emergency-established: 100
    emergency-bypassed: 50
  icmp:
    new: 30
    established: 300
    bypassed: 100
    emergency-new: 10
    emergency-established: 100
    emergency-bypassed: 50

# Stream engine settings. Here the TCP stream tracking and reassembly
# engine is configured.
#
# stream:
#   memcap: 64mb                # Can be specified in kb, mb, gb.  Just a
#                               # number indicates it's in bytes.
#   memcap-policy: ignore       # Can be "drop-flow", "pass-flow", "bypass",
#                               # "drop-packet", "pass-packet", "reject" or
#                               # "ignore" default is "ignore"
#   checksum-validation: yes    # To validate the checksum of received
#                               # packet. If csum validation is specified as
#                               # "yes", then packets with invalid csum values will not
#                               # be processed by the engine stream/app layer.
#                               # Warning: locally generated traffic can be
#                               # generated without checksum due to hardware offload
#                               # of checksum. You can control the handling of checksum
#                               # on a per-interface basis via the 'checksum-checks'
#                               # option
#   prealloc-sessions: 2k       # 2k sessions prealloc'd per stream thread
#   midstream: false            # don't allow midstream session pickups
#   midstream-policy: ignore    # Can be "drop-flow", "pass-flow", "bypass",
#                               # "drop-packet", "pass-packet", "reject" or
#                               # "ignore" default is "ignore"
#   async-oneside: false        # don't enable async stream handling
#   inline: no                  # stream inline mode
#   drop-invalid: yes           # in inline mode, drop packets that are invalid with regards to streaming engine
#   max-synack-queued: 5        # Max different SYN/ACKs to queue
#   bypass: no                  # Bypass packets when stream.reassembly.depth is reached.
#                               # Warning: first side to reach this triggers
#                               # the bypass.
#
#   reassembly:
#     memcap: 256mb             # Can be specified in kb, mb, gb.  Just a number
#                               # indicates it's in bytes.
#     memcap-policy: ignore     # Can be "drop-flow", "pass-flow", "bypass",
#                               # "drop-packet", "pass-packet", "reject" or
#                               # "ignore" default is "ignore"
#     depth: 1mb                # Can be specified in kb, mb, gb.  Just a number
#                               # indicates it's in bytes.
#     toserver-chunk-size: 2560 # inspect raw stream in chunks of at least
#                               # this size.  Can be specified in kb, mb,
#                               # gb.  Just a number indicates it's in bytes.
#     toclient-chunk-size: 2560 # inspect raw stream in chunks of at least
#                               # this size.  Can be specified in kb, mb,
#                               # gb.  Just a number indicates it's in bytes.
#     randomize-chunk-size: yes # Take a random value for chunk size around the specified value.
#                               # This lowers the risk of some evasion techniques but could lead
#                               # to detection change between runs. It is set to 'yes' by default.
#     randomize-chunk-range: 10 # If randomize-chunk-size is active, the value of chunk-size is
#                               # a random value between (1 - randomize-chunk-range/100)*toserver-chunk-size
#                               # and (1 + randomize-chunk-range/100)*toserver-chunk-size and the same
#                               # calculation for toclient-chunk-size.
#                               # Default value of randomize-chunk-range is 10.
#
#     raw: yes                  # 'Raw' reassembly enabled or disabled.
#                               # raw is for content inspection by detection
#                               # engine.
#
#     segment-prealloc: 2048    # number of segments preallocated per thread
#
#     check-overlap-different-data: true|false
#                               # check if a segment contains different data
#                               # than what we've already seen for that
#                               # position in the stream.
#                               # This is enabled automatically if inline mode
#                               # is used or when stream-event:reassembly_overlap_different_data;
#                               # is used in a rule.
#
stream:
  memcap: 64mb
  #memcap-policy: ignore
  checksum-validation: yes      # reject incorrect csums
  #midstream: false
  #midstream-policy: ignore
  inline: auto                  # auto will use inline mode in IPS mode, yes or no set it statically
  reassembly:
    memcap: 256mb
    #memcap-policy: ignore
    depth: 1mb                  # reassemble 1mb into a stream
    toserver-chunk-size: 2560
    toclient-chunk-size: 2560
    randomize-chunk-size: yes
    #randomize-chunk-range: 10
    #raw: yes
    #segment-prealloc: 2048
    #check-overlap-different-data: true

# Host table:
#
# Host table is used by the tagging and per host thresholding subsystems.
#
host:
  hash-size: 4096
  prealloc: 1000
  memcap: 32mb

# IP Pair table:
#
# Used by xbits 'ippair' tracking.
#
#ippair:
#  hash-size: 4096
#  prealloc: 1000
#  memcap: 32mb

# Decoder settings

decoder:
  # Teredo decoder is known to not be completely accurate
  # as it will sometimes detect non-teredo as teredo.
  teredo:
    enabled: true
    # ports to look for Teredo. Max 4 ports. If no ports are given, or
    # the value is set to 'any', Teredo detection runs on _all_ UDP packets.
    ports: $TEREDO_PORTS # syntax: '[3544, 1234]' or '3533' or 'any'.

  # VXLAN decoder is assigned to up to 4 UDP ports. By default only the
  # IANA assigned port 4789 is enabled.
  vxlan:
    enabled: true
    ports: $VXLAN_PORTS # syntax: '[8472, 4789]' or '4789'.

  # VNTag decode support
  vntag:
    enabled: false

  # Geneve decoder is assigned to up to 4 UDP ports. By default only the
  # IANA assigned port 6081 is enabled.
  geneve:
    enabled: true
    ports: $GENEVE_PORTS # syntax: '[6081, 1234]' or '6081'.

  # maximum number of decoder layers for a packet
  # max-layers: 16

##
## Performance tuning and profiling
##

# The detection engine builds internal groups of signatures. The engine
# allows us to specify the profile to use for them, to manage memory in an
# efficient way keeping good performance. For the profile keyword you
# can use the words "low", "medium", "high" or "custom". If you use custom,
# make sure to define the values in the "custom-values" section.
# Usually you would prefer medium/high/low.
#
# "sgh mpm-context", indicates how the staging should allot mpm contexts for
# the signature groups.  "single" indicates the use of a single context for
# all the signature group heads.  "full" indicates a mpm-context for each
# group head.  "auto" lets the engine decide the distribution of contexts
# based on the information the engine gathers on the patterns from each
# group head.
#
# The option inspection-recursion-limit is used to limit the recursive calls
# in the content inspection code.  For certain payload-sig combinations, we
# might end up taking too much time in the content inspection code.
# If the argument specified is 0, the engine uses an internally defined
# default limit.  When a value is not specified, there are no limits on the recursion.
detect:
  profile: medium
  custom-values:
    toclient-groups: 3
    toserver-groups: 25
  sgh-mpm-context: auto
  inspection-recursion-limit: 3000
  # If set to yes, the loading of signatures will be made after the capture
  # is started. This will limit the downtime in IPS mode.
  #delayed-detect: yes

  prefilter:
    # default prefiltering setting. "mpm" only creates MPM/fast_pattern
    # engines. "auto" also sets up prefilter engines for other keywords.
    # Use --list-keywords=all to see which keywords support prefiltering.
    default: mpm

  # the grouping values above control how many groups are created per
  # direction. Port whitelisting forces that port to get its own group.
  # Very common ports will benefit, as well as ports with many expensive
  # rules.
  grouping:
    #tcp-whitelist: 53, 80, 139, 443, 445, 1433, 3306, 3389, 6666, 6667, 8080
    #udp-whitelist: 53, 135, 5060

  profiling:
    # Log the rules that made it past the prefilter stage, per packet
    # default is off. The threshold setting determines how many rules
    # must have made it past pre-filter for that rule to trigger the
    # logging.
    #inspect-logging-threshold: 200
    grouping:
      dump-to-disk: false
      include-rules: false      # very verbose
      include-mpm-stats: false

# Select the multi pattern algorithm you want to run for scan/search the
# in the engine.
#
# The supported algorithms are:
# "ac"      - Aho-Corasick, default implementation
# "ac-bs"   - Aho-Corasick, reduced memory implementation
# "ac-ks"   - Aho-Corasick, "Ken Steele" variant
# "hs"      - Hyperscan, available when built with Hyperscan support
#
# The default mpm-algo value of "auto" will use "hs" if Hyperscan is
# available, "ac" otherwise.
#
# The mpm you choose also decides the distribution of mpm contexts for
# signature groups, specified by the conf - "detect.sgh-mpm-context".
# Selecting "ac" as the mpm would require "detect.sgh-mpm-context"
# to be set to "single", because of ac's memory requirements, unless the
# ruleset is small enough to fit in memory, in which case one can
# use "full" with "ac".  The rest of the mpms can be run in "full" mode.

mpm-algo: auto

# Select the matching algorithm you want to use for single-pattern searches.
#
# Supported algorithms are "bm" (Boyer-Moore) and "hs" (Hyperscan, only
# available if Suricata has been built with Hyperscan support).
#
# The default of "auto" will use "hs" if available, otherwise "bm".

spm-algo: auto

# Suricata is multi-threaded. Here the threading can be influenced.
threading:
  set-cpu-affinity: no
  # Tune cpu affinity of threads. Each family of threads can be bound
  # to specific CPUs.
  #
  # These 2 apply to the all runmodes:
  # management-cpu-set is used for flow timeout handling, counters
  # worker-cpu-set is used for 'worker' threads
  #
  # Additionally, for autofp these apply:
  # receive-cpu-set is used for capture threads
  # verdict-cpu-set is used for IPS verdict threads
  #
  cpu-affinity:
    - management-cpu-set:
        cpu: [ 0 ]  # include only these CPUs in affinity settings
    - receive-cpu-set:
        cpu: [ 0 ]  # include only these CPUs in affinity settings
    - worker-cpu-set:
        cpu: [ "all" ]
        mode: "exclusive"
        # Use explicitly 3 threads and don't compute number by using
        # detect-thread-ratio variable:
        # threads: 3
        prio:
          low: [ 0 ]
          medium: [ "1-2" ]
          high: [ 3 ]
          default: "medium"
    #- verdict-cpu-set:
    #    cpu: [ 0 ]
    #    prio:
    #      default: "high"
  #
  # By default Suricata creates one "detect" thread per available CPU/CPU core.
  # This setting allows controlling this behaviour. A ratio setting of 2 will
  # create 2 detect threads for each CPU/CPU core. So for a dual core CPU this
  # will result in 4 detect threads. If values below 1 are used, less threads
  # are created. So on a dual core CPU a setting of 0.5 results in 1 detect
  # thread being created. Regardless of the setting at a minimum 1 detect
  # thread will always be created.
  #
  detect-thread-ratio: 1.0
  #
  # By default, the per-thread stack size is left to its default setting. If
  # the default thread stack size is too small, use the following configuration
  # setting to change the size. Note that if any thread's stack size cannot be
  # set to this value, a fatal error occurs.
  #
  # Generally, the per-thread stack-size should not exceed 8MB.
  #stack-size: 8mb

# Luajit has a strange memory requirement, its 'states' need to be in the
# first 2G of the process' memory.
#
# 'luajit.states' is used to control how many states are preallocated.
# State use: per detect script: 1 per detect thread. Per output script: 1 per
# script.
luajit:
  states: 128

# Profiling settings. Only effective if Suricata has been built with
# the --enable-profiling configure flag.
#
profiling:
  # Run profiling for every X-th packet. The default is 1, which means we
  # profile every packet. If set to 1000, one packet is profiled for every
  # 1000 received.
  #sample-rate: 1000

  # rule profiling
  rules:

    # Profiling can be disabled here, but it will still have a
    # performance impact if compiled in.
    enabled: yes
    filename: rule_perf.log
    append: yes

    # Sort options: ticks, avgticks, checks, matches, maxticks
    # If commented out all the sort options will be used.
    #sort: avgticks

    # Limit the number of sids for which stats are shown at exit (per sort).
    limit: 10

    # output to json
    json: yes

  # per keyword profiling
  keywords:
    enabled: yes
    filename: keyword_perf.log
    append: yes

  prefilter:
    enabled: yes
    filename: prefilter_perf.log
    append: yes

  # per rulegroup profiling
  rulegroups:
    enabled: yes
    filename: rule_group_perf.log
    append: yes

  # packet profiling
  packets:

    # Profiling can be disabled here, but it will still have a
    # performance impact if compiled in.
    enabled: yes
    filename: packet_stats.log
    append: yes

    # per packet csv output
    csv:

      # Output can be disabled here, but it will still have a
      # performance impact if compiled in.
      enabled: no
      filename: packet_stats.csv

  # profiling of locking. Only available when Suricata was built with
  # --enable-profiling-locks.
  locks:
    enabled: no
    filename: lock_stats.log
    append: yes

  pcap-log:
    enabled: no
    filename: pcaplog_stats.log
    append: yes

##
## 网络过滤器集成 (默认)
##

# When running in NFQ inline mode, it is possible to use a simulated
# non-terminal NFQUEUE verdict.
# This permits sending all needed packet to Suricata via this rule:
#        iptables -I FORWARD -m mark ! --mark $MARK/$MASK -j NFQUEUE
# And below, you can have your standard filtering ruleset. To activate
# this mode, you need to set mode to 'repeat'
# If you want a packet to be sent to another queue after an ACCEPT decision
# set the mode to 'route' and set next-queue value.
# On Linux >= 3.1, you can set batchcount to a value > 1 to improve performance
# by processing several packets before sending a verdict (worker runmode only).
# On Linux >= 3.6, you can set the fail-open option to yes to have the kernel
# accept the packet if Suricata is not able to keep pace.
# bypass mark and mask can be used to implement NFQ bypass. If bypass mark is
# set then the NFQ bypass is activated. Suricata will set the bypass mark/mask
# on packet of a flow that need to be bypassed. The Nefilter ruleset has to
# directly accept all packets of a flow once a packet has been marked.
nfq:
#  mode: accept
#  repeat-mark: 1
#  repeat-mask: 1
#  bypass-mark: 1
#  bypass-mask: 1
#  route-queue: 2
#  batchcount: 20
#  fail-open: yes

#nflog support
nflog:
    # netlink multicast group
    # (the same as the iptables --nflog-group param)
    # Group 0 is used by the kernel, so you can't use it
  - group: 2
    # netlink buffer size
    buffer-size: 18432
    # put default value here
  - group: default
    # set number of packets to queue inside kernel
    qthreshold: 1
    # set the delay before flushing packet in the kernel's queue
    qtimeout: 100
    # netlink max buffer size
    max-size: 20000

##
## 高级捕获选项 (默认)
##

# 影响数据包捕获的常规设置
capture:
  # 禁用NIC卸载. suricata退出后恢复.
  # Enabled 是默认.
  #disable-offloading: false
  #
  # 禁用校验和验证. 与设置相同 '-k none' 在命令行上.
  #checksum-validation: none

# Netmap 支持
#
# 一些netmap的说明,译者删除了
# 您可以在找到更多信息 https://github.com/luigirizzo/netmap
#
netmap:
   # 网卡设置
   # 要指定OS端点，请在端点处添加加号 (e.g. "eth0+")
 - interface: eth2
   # 捕获线程数 "auto"使用界面上的RSS队列数
   # Warning: 除非RSS哈希是对称的，否则这将导致准确性问题
   #threads: auto
   # 您可以使用以下变量激活网络映射抽头或IPS模式
   # 如果复制模式设置为ips或tap，则到达当前接口的流量将复制到copy-iface接口
   # 如果设置了 'tap' 则复制完成
   # 如果设置了 'ips' i则不会复制与“drop”操作匹配的数据包
   # 要将操作系统指定为 copy-iface (这样操作系统就可以路由数据包或转发到同一台机器上运行的服务) 请在末尾添加加号  (e.g. "copy-iface: eth0+")
   # 不要忘记为返回数据包设置一个对称的 eth0+ -> eth0
   # 如果使用OS endpoint，则接口上的硬件校验和必须为 *off* (e.g. 'ifconfig eth0 -rxcsum -txcsum -rxcsum6 -txcsum6' for FreeBSD or 'ethtool -K eth0 tx off rx off' for Linux).
   #copy-mode: tap
   #copy-iface: eth3
   # 设置为 yes 可禁用混杂模式
   # disable-promisc: no
   # 为接口选择校验和验证模式
   # 在捕获的时刻 由于校验和计算被卸载到网卡 一些分组可能具有无效的校验和
   # 可能的值为:
   #  - yes: 强制进行校验和验证
   #  - no: 校验和验证被禁用
   #  - auto: suricata使用统计方法来检测何时使用校验和卸载
   # 警告: 'checksum-validation' 必须设置为 yes 才能进行任何验证
   #checksum-checks: auto
   # 应用于此接口的BPF筛选器 此处应用pcap筛选器语法
   #bpf-filter: port 80 or udp
 #- interface: eth3
   #threads: auto
   #copy-mode: tap
   #copy-iface: eth2
   # Put default values here
 - interface: default

# PF_RING 配置: 用于与本机PF_RING支持一起使用
# 您可以在找到更多信息 http://www.ntop.org/products/pf_ring/
pfring:
    # 网卡设置
  - interface: eth0
    # 接收线程数. 如果设置为 'auto' Suricata将首先尝试使用CPU核心计数，否则将使用RSS队列计数
    threads: auto

    # 默认集群.  PF_RING 将根据流对数据包进行负载平衡
    # 所有将参与的线程/进程都需要具有相同的
    # clusterid.
    cluster-id: 99

    # 默认 PF_RING 群集类型. 可以对每个流进行负载平衡
    # 可能的值为 cluster_flow 或 cluster_round_robin.
    cluster-type: cluster_flow

    # 此接口的bpf筛选器
    #bpf-filter: tcp

    # 如果设置了旁路 则在网络接口支持时激活PF_RING hw旁路
    # Suricata将指示接口绕过需要绕过的流的所有未来数据包
    #bypass: yes

    # 为接口选择校验和验证模式.
    # 捕获的那一刻, 由于校验和计算被卸载到网卡，一些数据包可能具有无效的校验和
    # 可能的值为:
    #  - rxonly: 仅计算网卡接收的数据包的校验和
    #  - yes: 强制进行校验和验证
    #  - no: 校验和验证被禁用
    #  - auto: suricata使用统计方法来检测何时使用校验和卸载 (default)
    # Warning: 'checksum-validation' 必须设置为 yes 才能进行任何验证
    #checksum-checks: auto
  # 第二个接口
  #- interface: eth1
  #  threads: 3
  #  cluster-id: 93
  #  cluster-type: cluster_flow
  # 在此处放置默认值
  - interface: default
    #threads: 2

# 对 FreeBSD ipfw(8) divert(4) 的支持.
# 请确保您有 ipfw_load="YES" 和 ipdivert_load="YES"
# 在 /etc/loader.conf 或 kldload'中加载适当的内核模块.
# 此外，您需要为引擎提供一个ipfw规则，以查看来自ipfw的数据包
# 例如:
#
#   ipfw add 100 divert 8000 ip from any to any
#
# N.B. This example uses "8000" -- this number must mach the values
# you passed on the command line, i.e., -d 8000
#
ipfw:

  # Reinject packets at the specified ipfw rule number.  This config
  # option is the ipfw rule number AT WHICH rule processing continues
  # in the ipfw processing system after the engine has finished
  # inspecting the packet for acceptance.  If no rule number is specified,
  # accepted packets are reinjected at the divert rule which they entered
  # and IPFW rule processing continues.  No check is done to verify
  # this will rule makes sense so care must be taken to avoid loops in ipfw.
  #
  ## The following example tells the engine to reinject packets
  # back into the ipfw firewall AT rule number 5500:
  #
  # ipfw-reinjection-rule-number: 5500


napatech:
    # When use_all_streams is set to "yes" the initialization code will query
    # the Napatech service for all configured streams and listen on all of them.
    # When set to "no" the streams config array will be used.
    #
    # This option necessitates running the appropriate NTPL commands to create
    # the desired streams prior to running Suricata.
    #use-all-streams: no

    # The streams to listen on when auto-config is disabled or when and threading
    # cpu-affinity is disabled.  This can be either:
    #   an individual stream (e.g. streams: [0])
    # or
    #   a range of streams (e.g. streams: ["0-3"])
    #
    streams: ["0-3"]

    # Stream stats can be enabled to provide fine grain packet and byte counters
    # for each thread/stream that is configured.
    #
    enable-stream-stats: no

    # When auto-config is enabled the streams will be created and assigned
    # automatically to the NUMA node where the thread resides.  If cpu-affinity
    # is enabled in the threading section.  Then the streams will be created
    # according to the number of worker threads specified in the worker-cpu-set.
    # Otherwise, the streams array is used to define the streams.
    #
    # This option is intended primarily to support legacy configurations.
    #
    # This option cannot be used simultaneously with either "use-all-streams"
    # or "hardware-bypass".
    #
    auto-config: yes

    # Enable hardware level flow bypass.
    #
    hardware-bypass: yes

    # Enable inline operation.  When enabled traffic arriving on a given port is
    # automatically forwarded out its peer port after analysis by Suricata.
    #
    inline: no

    # Ports indicates which Napatech ports are to be used in auto-config mode.
    # these are the port IDs of the ports that will be merged prior to the
    # traffic being distributed to the streams.
    #
    # When hardware-bypass is enabled the ports must be configured as a segment.
    # specify the port(s) on which upstream and downstream traffic will arrive.
    # This information is necessary for the hardware to properly process flows.
    #
    # When using a tap configuration one of the ports will receive inbound traffic
    # for the network and the other will receive outbound traffic. The two ports on a
    # given segment must reside on the same network adapter.
    #
    # When using a SPAN-port configuration the upstream and downstream traffic
    # arrives on a single port. This is configured by setting the two sides of the
    # segment to reference the same port.  (e.g. 0-0 to configure a SPAN port on
    # port 0).
    #
    # port segments are specified in the form:
    #    ports: [0-1,2-3,4-5,6-6,7-7]
    #
    # For legacy systems when hardware-bypass is disabled this can be specified in any
    # of the following ways:
    #
    #   a list of individual ports (e.g. ports: [0,1,2,3])
    #
    #   a range of ports (e.g. ports: [0-3])
    #
    #   "all" to indicate that all ports are to be merged together
    #   (e.g. ports: [all])
    #
    # This parameter has no effect if auto-config is disabled.
    #
    ports: [0-1,2-3]

    # When auto-config is enabled the hashmode specifies the algorithm for
    # determining to which stream a given packet is to be delivered.
    # This can be any valid Napatech NTPL hashmode command.
    #
    # The most common hashmode commands are:  hash2tuple, hash2tuplesorted,
    # hash5tuple, hash5tuplesorted and roundrobin.
    #
    # See Napatech NTPL documentation other hashmodes and details on their use.
    #
    # This parameter has no effect if auto-config is disabled.
    #
    hashmode: hash5tuplesorted

##
## Suricata更新托管规则.
##

default-rule-path: /etc/suricata/rules

rule-files:
  - suricata.rules
#  - app-layer-events.rules
#  - dns-events.rules
#  - ipsec-events.rules
#  - nfs-events.rules
#  - ssh-events.rules
#  - decoder-events.rules
#  - files.rules
#  - kerberos-events.rules
#  - ntp-events.rules
#  - stream-events.rules
#  - dhcp-events.rules
#  - http2-events.rules
#  - modbus-events.rules
#  - smb-events.rules
#  - dnp3-events.rules
#  - http-events.rules
#  - mqtt-events.rules
#  - smtp-events.rules
#  - tls-events.rules


##
## 辅助配置文件
##

classification-file: /etc/suricata/classification.config
reference-config-file: /etc/suricata/reference.config
threshold-file: /etc/suricata/threshold.config

##
## 包括其他配置 
##


# 导入其他文件,可以使用绝对路径跟相对路径
#include: include1.yaml
#include: include2.yaml